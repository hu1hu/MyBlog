<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>高性能云计算复习 | My学习之路</title><meta name="author" content="hu1hu,3261801992@qq.com"><meta name="copyright" content="hu1hu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="并行计算概述什么是并行计算？并行计算（Parallel Computing）,同义词：高性能计算（High Performance Computing）、超级计算（Super Computing）   ​	在并行机上，将一个应用分解成多个子任务，分配给不同的处理器，各个处理器之间相互协同，并行地执行子任务，从而达到加速求解速度，或者求解应用问题。 基本条件 硬件（并行机）： 并行机至少包含两台或两">
<meta property="og:type" content="article">
<meta property="og:title" content="高性能云计算复习">
<meta property="og:url" content="https://www.hu1hu.top/posts/idek234jld/index.html">
<meta property="og:site_name" content="My学习之路">
<meta property="og:description" content="并行计算概述什么是并行计算？并行计算（Parallel Computing）,同义词：高性能计算（High Performance Computing）、超级计算（Super Computing）   ​	在并行机上，将一个应用分解成多个子任务，分配给不同的处理器，各个处理器之间相互协同，并行地执行子任务，从而达到加速求解速度，或者求解应用问题。 基本条件 硬件（并行机）： 并行机至少包含两台或两">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/R.jpg">
<meta property="article:published_time" content="2024-01-04T16:00:00.000Z">
<meta property="article:modified_time" content="2024-01-05T11:30:17.687Z">
<meta property="article:author" content="hu1hu">
<meta property="article:tag" content="高性能云计算">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.hu1hu.top/posts/idek234jld/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '高性能云计算复习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-05 19:30:17'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/header-numbering.css"><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/R.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="My学习之路"><span class="site-name">My学习之路</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">高性能云计算复习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-04T16:00:00.000Z" title="发表于 2024-01-05 00:00:00">2024-01-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-05T11:30:17.687Z" title="更新于 2024-01-05 19:30:17">2024-01-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%85%B6%E5%AE%83/">其它</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="高性能云计算复习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="并行计算概述"><a href="#并行计算概述" class="headerlink" title="并行计算概述"></a>并行计算概述</h2><h3 id="什么是并行计算？"><a href="#什么是并行计算？" class="headerlink" title="什么是并行计算？"></a>什么是并行计算？</h3><p>并行计算（Parallel Computing）,同义词：高性能计算（High Performance Computing）、超级计算（Super Computing）</p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226115253294.png" alt="image-20231226115253294" style="zoom:0%;" />

<p>​	在并行机上，将一个应用分解成多个子任务，分配给不同的处理器，各个处理器之间相互协同，并行地执行子任务，从而达到加速求解速度，或者求解应用问题。</p>
<h3 id="基本条件"><a href="#基本条件" class="headerlink" title="基本条件"></a>基本条件</h3><ol>
<li><p><strong>硬件（并行机）：</strong></p>
<p>并行机至少包含两台或两台以上处理机，这些处理机通过互连网络相互连接，相互通信。</p>
</li>
<li><p><strong>并行算法设计：</strong></p>
<p>也就是说，应用可以分解为多个子任务，这些子任务可以并行地执行。将一个应用分解为多个子任务的过程，称为并行算法的设计。</p>
</li>
<li><p><strong>并行编程环境：</strong></p>
<p>在并行机提供的并行编程环境上，具体实现并行算法，编制并行程序，并运行该程序，从而达到并行求解应用问题的目的。</p>
</li>
</ol>
<h3 id="主要目标"><a href="#主要目标" class="headerlink" title="主要目标"></a>主要目标</h3><ol>
<li><p><strong>提高求解速度：</strong></p>
<p>例如，在单处理器上，串行执行需要2 个星期（14 天），借助并行计算，使用100 台处理器，加速50 倍，将执行时间缩短为6.72 个小时。</p>
</li>
<li><p><strong>扩大问题规模：</strong></p>
<p>例如，在单处理器上，受内存资源2GB的限制，只能计算10 万个网格，也可以借助并行计算，使用100 个处理器，将问题求解规模线性地扩大100 倍。</p>
</li>
</ol>
<h2 id="并行计算体系结构（1）"><a href="#并行计算体系结构（1）" class="headerlink" title="并行计算体系结构（1）"></a>并行计算体系结构（1）</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><h4 id="并行计算机网络性能指标"><a href="#并行计算机网络性能指标" class="headerlink" title="并行计算机网络性能指标"></a>并行计算机网络性能指标</h4><ul>
<li><p><strong>节点度（Node Degree）</strong>：射入或射出一个节点的边数。在单向网络中，入射和出射边之和称为节点度。</p>
</li>
<li><p><strong>网络直径（Network Diameter）</strong>： 网络中任何两个节点之间的最长距离，即最大路径数。</p>
</li>
<li><p><strong>对剖宽度（Bisection Width）</strong> ：对分网络各半所必须移去的最少边数</p>
</li>
<li><p>如果从任一节点观看网络都一样，则称网络为<strong>对称的（Symmetry）</strong> </p>
</li>
<li><p><strong>对剖带宽（ Bisection Bandwidth）</strong>:每秒钟内，在最小的对剖平面上通过所有连线的最大信息位（或字节）数</p>
</li>
<li><p><strong>网络规模</strong>：网络包含的结点总数，或者包含的CPU 总数。</p>
</li>
</ul>
<p>​	在固定网络规模的情况下，对剖带宽越高、对剖宽度越大、网络直径越小，则互联网络的质量就越高。</p>
<h3 id="静态互联网络"><a href="#静态互联网络" class="headerlink" title="静态互联网络"></a>静态互联网络</h3><h4 id="静态连接"><a href="#静态连接" class="headerlink" title="静态连接"></a>静态连接</h4><blockquote>
<p>处理单元间有着固定连接的一类网络，在程序执行期间，这种点到点的链接保持不变</p>
</blockquote>
<p>• 典型的静态网络</p>
<p><strong>一维线性阵列</strong>、<strong>二维网孔</strong>、<strong>树连接</strong>、<strong>超立方网络</strong>、<strong>立方环</strong>等。</p>
<h4 id="一维线性阵列"><a href="#一维线性阵列" class="headerlink" title="一维线性阵列"></a>一维线性阵列</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226135837823.png" alt="image-20231226135837823" style="zoom:70%;" />

<h4 id="二维网孔"><a href="#二维网孔" class="headerlink" title="二维网孔"></a>二维网孔</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226140100808.png" alt="image-20231226140100808" style="zoom:70%;" />

<p><strong>改进：</strong></p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226140415464.png" alt="image-20231226140415464" style="zoom:70%;" />



<h4 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226140952854.png" alt="image-20231226140952854" style="zoom:67%;" />

<ul>
<li><p><strong>标准二叉树拓扑结构包含P&#x3D;2^N个叶结点和2^N-1个内结点</strong></p>
<ul>
<li><p><strong>叶结点分别对应并行机的结点；</strong></p>
</li>
<li><p><strong>内结点负责这些叶结点之间的通信。</strong></p>
</li>
</ul>
</li>
<li><p><strong>二叉树的网络直径仅为2 log P，非常有利于叶结点之间的全局通信。</strong></p>
</li>
<li><p><strong>它的折半宽度只为1，不利于结点之间的大数据量通信。</strong></p>
</li>
</ul>
<p><strong>改进：</strong>（胖树）</p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226141324784.png" alt="image-20231226141324784" style="zoom:67%;" />

<h4 id="超立方"><a href="#超立方" class="headerlink" title="超立方"></a>超立方</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226141805807.png" alt="image-20231226141805807" style="zoom:67%;" />

<ul>
<li>是一个具有很好性质的拓扑结构，其网络直径仅为logP，折半带宽为2^(d-1)。</li>
<li>结点的度为d，随并行机规模的增加而增加，这给网络实现带来了一定的困难。</li>
<li>通常地，超立方体一般不超过5 维。</li>
</ul>
<h4 id="k-立方环"><a href="#k-立方环" class="headerlink" title="k-立方环"></a>k-立方环</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226142359184.png" alt="image-20231226142359184" style="zoom:67%;" />



<h4 id="静态互联网络特性比较（记）"><a href="#静态互联网络特性比较（记）" class="headerlink" title="静态互联网络特性比较（记）"></a>静态互联网络特性比较（记）</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231226141546978.png" alt="image-20231226141546978"></p>
<h3 id="动态互联网络"><a href="#动态互联网络" class="headerlink" title="动态互联网络"></a>动态互联网络</h3><p>···</p>
<h2 id="并行计算体系结构（2）"><a href="#并行计算体系结构（2）" class="headerlink" title="并行计算体系结构（2）"></a>并行计算体系结构（2）</h2><h3 id="Flynn分类"><a href="#Flynn分类" class="headerlink" title="Flynn分类"></a>Flynn分类</h3><p>指令流&#x2F;数据流分类法，即<strong>费林-Flynn</strong>分类法。（计算机系统分类）</p>
<p>（1）<strong>指令流（Instruction Stream）</strong>：机器执行的指令序列。</p>
<p>（2）<strong>数据流（Data Stream）</strong>：指令调用的数据序列，包括输入数据和中间结果。</p>
<p>（3）<strong>多倍性（Multiplicity）</strong>：在系统性能瓶颈部件上同时处于同一执行阶段的指令或数据的最大可能个数。</p>
<hr>
<p>• 两个独立的维度——指令流和数据流的不同组织方式，将<strong>计算机系统</strong>分为四类：</p>
<ul>
<li><p>单指令单数据流（Single Instruction stream and Single Data stream , SISD）系统</p>
</li>
<li><p>单指令多数据流（Single Instruction stream and Multiple-Data stream , SIMD）系统</p>
</li>
<li><p>多指令单数据流（Multiple-Instruction stream and Single Data stream , MISD）系统</p>
</li>
<li><p>多指令多数据流（Multiple-Instruction stream and Multiple-Data stream , MIMD）系统</p>
</li>
</ul>
<p>• SISD：SISD系统是一种传统的顺序执行的单处理器计算机，它的硬件不支持任何形式的并行计算，所有的指令都是串行执行。在任何一个时钟周期内，CPU只能处理一个数据流，因此这种机器被称作单指令流单数据流机器</p>
<p>• SIMD：SIMD系统有多个处理单元，由单一的指令部件控制，按照同一指令流的要求为它们分配各不相同的数据流并进行处理。系统结构由一个控制器、多个处理器、多个存储模块和一个互连总线（网络）组成</p>
<p>• MISD：MISD系统有多个处理单元，每个处理单元按照多条不同的指令要求同时对同一数据流及其处理输出的结果进行不同的处理，把一个单元的输出作为另一个单元的输入</p>
<p>• MIMD ：MIMD系统又称为多处理机系统，是指能实现指令、数据作业、任务等各级全面并行计算的多机处理系统，可以将一个主任务分解为众多子任务并行执行以缩短工作时间</p>
<h3 id="内存访问模型"><a href="#内存访问模型" class="headerlink" title="内存访问模型"></a>内存访问模型</h3><h4 id="并行计算机的体系结构"><a href="#并行计算机的体系结构" class="headerlink" title="并行计算机的体系结构"></a>并行计算机的体系结构</h4><ul>
<li>组成要素<ul>
<li><strong>处理器（processor）</strong>:计算单元</li>
<li><strong>互联网络（interconnect network）</strong>:连接</li>
<li><strong>内存（memory）</strong>:多个存储模块的组成</li>
</ul>
</li>
</ul>
<p>并行机的基本特征是具备多个<strong>计算单元</strong>和<strong>存储模块</strong>，各个模块通过互联网络耦合</p>
<ul>
<li>根据耦合的紧密程度可分为紧耦合和松耦合。</li>
<li>不同的并行计算机，其各模块耦合的松紧程度可以有区别</li>
</ul>
<h4 id="共享内存vs分布式内存"><a href="#共享内存vs分布式内存" class="headerlink" title="共享内存vs分布式内存"></a>共享内存vs分布式内存</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227122738905.png" alt="image-20231227122738905" style="zoom:60%;" />

<h4 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227131409871.png" alt="image-20231227131409871" style="zoom:70%;" />

<p>​	通常也称为紧密耦合多处理机，它具有一个所有处理器都可以访问的全局物理内存。</p>
<p><strong>共享内存系统的特性有：</strong></p>
<ol>
<li><strong>对称性</strong>：系统中任何处理器都可以访问任何的内存单元和I&#x2F;O设备</li>
<li><strong>单地址空间</strong>：内存中每一个位置在整个的内存地址范围内有一个唯一的地址</li>
<li><strong>低通信延迟</strong>：处理器间的通信可以利用共享内存来进行数据交换</li>
<li><strong>高速缓存及其一致性</strong>：多级高速缓存可以支持数据的局部性，而其一致性可由硬件来增强</li>
</ol>
<h4 id="分布式内存"><a href="#分布式内存" class="headerlink" title="分布式内存"></a>分布式内存</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227162708832.png" alt="image-20231227162708832"></p>
<ul>
<li>分布式内存系统中处理器都有各自的内部寄存器，一个核内的内存地址对其他核不可见，只能由该处理器所访问，对于所有CPU都没有单一全局地址空间的概念，这类的分布式计算机系统称为非远程存储访问（No-Remote Memory Access, NORMA）</li>
</ul>
<h4 id="并行计算机访问模型"><a href="#并行计算机访问模型" class="headerlink" title="并行计算机访问模型"></a>并行计算机访问模型</h4><ul>
<li>UMA（Uniform Memory Access）模型：均匀存储访问模型。</li>
<li>NUMA（Non-Uniform Memory Access）模型：非均匀存储访问模型。</li>
<li>COMA（Cache-Only Memory Access）模型：全高速缓存存储访问。</li>
<li>CC-NUMA（Coherent-Cache Nonuniform Memory Access）模型：高速缓存一致性非均匀存储访问模型。</li>
<li>NORMA（No-Remote Memory Access）模型：非远程存储访问模型。</li>
</ul>
<h4 id="UMA（Uniform-Memory-Access）"><a href="#UMA（Uniform-Memory-Access）" class="headerlink" title="UMA（Uniform Memory Access）"></a>UMA（Uniform Memory Access）</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227144312553.png" alt="image-20231227144312553"></p>
<ul>
<li><p>物理存储器被所有处理器均匀共享；</p>
</li>
<li><p>所有处理器访问任何存储字取相同的时间；</p>
</li>
<li><p>每台处理器可带私有高速缓存；</p>
</li>
<li><p>外围设备(I&#x2F;O)也可以一定形式共享；</p>
</li>
<li><p>发生访存竞争时，仲裁策略平等对待每个结点，即每个结点机会均等；</p>
</li>
</ul>
<h4 id="NUMA（Non-Uniform-Memory-Access）"><a href="#NUMA（Non-Uniform-Memory-Access）" class="headerlink" title="NUMA（Non-Uniform Memory Access）"></a>NUMA（Non-Uniform Memory Access）</h4><p>非均匀存储访问</p>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227160342362.png" alt="image-20231227160342362"></p>
<ul>
<li><p>被共享的存储器在物理上是分布在所有的处理器中的，其所有本地存储器的集合就组成了全局地址空间；</p>
</li>
<li><p>处理器访问存储器时间是不一样的；</p>
</li>
<li><p>每台处理器照例可带私有高速缓存。</p>
</li>
</ul>
<h4 id="CC-NUMA（高速缓存一致性非均匀存储访问模型）"><a href="#CC-NUMA（高速缓存一致性非均匀存储访问模型）" class="headerlink" title="CC-NUMA（高速缓存一致性非均匀存储访问模型）"></a>CC-NUMA（高速缓存一致性非均匀存储访问模型）</h4><p>Coherent-Cache Nonuniform Memory Access</p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227161724363.png" alt="image-20231227161724363" style="zoom: 70%;" />

<p><strong>特点：</strong></p>
<ul>
<li>大多数使用基于目录的高速缓存一致性协议；</li>
<li>保留SMP结构易于编程的优点，也改善常规SMP的扩张性；</li>
<li>CC-NUMA实际上是一个分布共享存储的DSM多处理机系统;</li>
<li>它最显著的优点是程序员无需明确地在节点上分配数据，系统的硬件和软件开始时自动在各节点分配数据，在运行期间，高速缓存一致性硬件会自动地将数据迁移至要用到它的地方。</li>
</ul>
<h4 id="COMA"><a href="#COMA" class="headerlink" title="COMA"></a>COMA</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227162513786.png" alt="image-20231227162513786" style="zoom:67%;" />

<p>特例：全高速缓存存储访问（Cache-Only Memory Access, COMA）模型，COMA各个处理器节点没有存储层次结构，所有节点的高速缓存构成了全局地址空间</p>
<h4 id="NORMA-（非远程存储访问）"><a href="#NORMA-（非远程存储访问）" class="headerlink" title="(NORMA)（非远程存储访问）"></a>(NORMA)（非远程存储访问）</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227162951105.png" alt="image-20231227162951105" style="zoom:50%;" />

<p><strong>优点：</strong></p>
<ol>
<li>内存可以随着CPU的数量进行扩展，增加处理器数量将使内存的大小等比例增加</li>
<li>各个处理器可以无冲突地快速访问自己的内存，也不存在维护缓存一致性的开销</li>
<li>成本效益上，可以使用商用、现成的处理器和网络</li>
</ol>
<p><strong>局限性：</strong></p>
<ol>
<li>程序员将要负责所有处理器间数据通信相关的细节问题</li>
<li>很难从基于全局内存空间的数据结构上建立起到分布式内存管理的映射。</li>
<li>非一致的内存访问时间使得驻留在远程节点上的数据比节点本地数据的访问需要更长时间。</li>
</ol>
<h4 id="PVP（Parallel-Vector-Processor）"><a href="#PVP（Parallel-Vector-Processor）" class="headerlink" title="PVP（Parallel Vector Processor）"></a>PVP（Parallel Vector Processor）</h4><p>并行向量处理器</p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227150433907.png" alt="image-20231227150433907" style="zoom: 80%;" />

<h4 id="SMP（Symmetric-Multiprocessing）"><a href="#SMP（Symmetric-Multiprocessing）" class="headerlink" title="SMP（Symmetric Multiprocessing）"></a>SMP（Symmetric Multiprocessing）</h4><p>对称多处理器</p>
<ul>
<li>内存模块和处理器对称地分布在互联网络的两侧; </li>
<li>内存访问属典型的均匀访问模型。</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227150541462.png" alt="image-20231227150541462"></p>
<p><strong>特点：</strong></p>
<p>优点：</p>
<ul>
<li><p>对称共享存储</p>
<p>系统中任何处理器均可直接访问任何存储模块中的存储单元和I&#x2F;O 模块，且访问的延迟、带宽和访问成功的概率是一致的。所有内存单元统一编址。各个处理器之间的地位等价，不存在任何特权处理器。操作系统可在任意处理器上运行。</p>
</li>
<li><p>单一的操作系统映像</p>
<p>全系统只有一个操作系统驻留在共享存储器中，它根据各个处理器的负载情况，动态地分配各个进程到各个处理器，并保持各处理器间的负载平衡。 </p>
</li>
<li><p>局部高速缓存cache 及其数据一致性</p>
<p>每个处理器均配备局部cache，它们可以拥有独立的局部数据，但是这些数据必须与存储器中的数据保持一致。</p>
</li>
<li><p>低通信延迟</p>
<p>各进程通过读&#x2F;写操作系统提供的共享数据缓存区来完成处理器间的通信，其延迟通常小于网络通信的延迟。</p>
</li>
<li><p>共享总线带宽</p>
<p>所有处理器共享总线的带宽，完成对内存模块和I&#x2F;O 模块的访问。 </p>
</li>
<li><p>支持消息传递、共享存储并行程序设计。</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li><p>欠可靠</p>
<p>总线、存储器或操作系统失效可导致系统崩溃。 </p>
</li>
<li><p>可扩展性（scalability）较差</p>
<p>由于所有处理器共享总线带宽，而总线带宽每3 年才增加2 倍，跟不上处理器速度和内存容量的增加步伐，因此，SMP 并行机的处理器个数一般少于32 个，且只能提供每秒数百亿次的浮点运算性能。</p>
</li>
</ul>
<h4 id="大规模并行处理机（Massively-Parallel-Processor，MPP）"><a href="#大规模并行处理机（Massively-Parallel-Processor，MPP）" class="headerlink" title="大规模并行处理机（Massively Parallel Processor，MPP）"></a>大规模并行处理机（Massively Parallel Processor，MPP）</h4><ul>
<li>由大规模“紧密”互连的节点组成的</li>
<li>内存访问属于非远程访问模型（NORMA）</li>
<li>也被称为“message-passing”系统</li>
</ul>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227170058680.png" alt="image-20231227170058680" style="zoom:50%;" />

<ul>
<li><p>由数百个乃至数千个计算结点和I&#x2F;O 结点组成，每个结点相对独立，并拥有一个或多个微处理器。</p>
<ul>
<li><p>这些结点配备有局部cache，并通过局部总线或互联网络与局部内存模块和I&#x2F;O设备相连接。</p>
</li>
<li><p>这些结点由局部高性能网卡(NIC)通过高性能互联网络相互连接。</p>
</li>
<li><p>各个结点均拥有不同的操作系统映像。</p>
<ul>
<li>一般情况下，用户可以将作业提交给作业管理系统，由它负责调度当前最空闲、最有效的计算结点来执行该作业。但是，MPP也允许用户登录到某个特定的结点，或在某些特定的结点上运行作业。</li>
</ul>
</li>
<li><p>各个结点间的内存模块相互独立，且不存在全局内存单元的统一硬件编址。</p>
</li>
<li><p>仅支持消息传递或者高性能Fortran并行程序设计，不支持全局共享的OpenMP并行程序设计模式。</p>
</li>
</ul>
</li>
</ul>
<h4 id="集群、机群（Cluster）-COW"><a href="#集群、机群（Cluster）-COW" class="headerlink" title="集群、机群（Cluster）&#x2F;COW"></a>集群、机群（Cluster）&#x2F;COW</h4><ul>
<li><p>松耦合。分布式存储，MIMD，工作站+商用互连网络，每个节点是一个完整的计算机，有自己的磁盘和操作系统。 </p>
</li>
<li><p>优点：</p>
<ul>
<li><p>投资风险小</p>
</li>
<li><p>系统结构灵活</p>
</li>
<li><p>性能&#x2F;价格比高</p>
</li>
<li><p>能充分利用分散的计算资源</p>
</li>
<li><p>可扩放性好</p>
</li>
</ul>
</li>
<li><p>问题</p>
<ul>
<li><p>通信性能</p>
</li>
<li><p>并行编程环境</p>
</li>
</ul>
</li>
</ul>
<p>例子：Berkeley NOW，Alpha Farm, FXCOW</p>
<h4 id="MPP-vs-Cluster"><a href="#MPP-vs-Cluster" class="headerlink" title="MPP vs Cluster"></a>MPP vs Cluster</h4><ul>
<li><p>Cluster的每个结点都是一台完整的计算机。 Cluster的每个结点上都有完整的操作系统，而MPP的每个结点上通常只有操作系统的微核。 Cluster的网络和操作系统均不是定制的。</p>
</li>
<li><p>Cluster的每个结点内有本地磁盘，而MPP的结点内没有。</p>
</li>
<li><p>Cluster各结点的网络接口是连接到I&#x2F;O总线上的（松耦合），而MPP各结点的网络接口是连接到存储总线上的（紧耦合）。</p>
</li>
</ul>
<h4 id="DSM（Distributed-Shared-Memory-，DSM）"><a href="#DSM（Distributed-Shared-Memory-，DSM）" class="headerlink" title="DSM（Distributed Shared Memory ，DSM）"></a>DSM（Distributed Shared Memory ，DSM）</h4><h4 id="内存体系"><a href="#内存体系" class="headerlink" title="内存体系"></a>内存体系</h4><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227151511495.png" alt="image-20231227151511495" style="zoom:80%;" />



<h4 id="五种结构特性"><a href="#五种结构特性" class="headerlink" title="五种结构特性"></a>五种结构特性</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231227145147243.png" alt="image-20231227145147243"></p>
<h2 id="并行计算模型及性能评测"><a href="#并行计算模型及性能评测" class="headerlink" title="并行计算模型及性能评测"></a>并行计算模型及性能评测</h2><h3 id="并行计算模型"><a href="#并行计算模型" class="headerlink" title="并行计算模型"></a>并行计算模型</h3><blockquote>
<p>将并行计算机的基本特征抽象出来，形成一个抽象的计算模型，作为并行算法分析、设计、性能预测的基础。</p>
</blockquote>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228152740124.png" alt="image-20231228152740124" style="zoom: 70%;" />

<h4 id="PRAM模型"><a href="#PRAM模型" class="headerlink" title="PRAM模型"></a>PRAM模型</h4><h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h5><blockquote>
<p>由Fortune和Wyllie1978年提出，又称SIMD-SM模型。有一个集中的共享存储器和一个指令控制器，通过SM的R&#x2F;W交换数据，隐式同步计算。</p>
</blockquote>
<p>Parallel Random Access Machine</p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228153658490.png" alt="image-20231228153658490" style="zoom:67%;" />

<p><strong>优点</strong></p>
<ul>
<li>适合并行算法表示和复杂性分析，易于使用，隐藏了并行机的通讯、同步等细节。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>不适合MIMD并行机，忽略了SM的竞争、通讯延迟等因素</li>
</ul>
<h4 id="BSP模型"><a href="#BSP模型" class="headerlink" title="BSP模型"></a>BSP模型</h4><h5 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h5><blockquote>
<p>由Valiant(1990)提出的，“块”同步模型，是一种异步MIMD-DM模型，支持消息传递系统，块内异步并行，块间显式同步。</p>
</blockquote>
<p><strong>模型参数：</strong></p>
<ul>
<li><p><em>p</em>：处理器数(带有存储器) </p>
</li>
<li><p><em>l</em>：同步障时间(Barrier synchronization time)</p>
</li>
<li><p><em>g</em>：带宽因子(time steps&#x2F;packet)&#x3D;1&#x2F;bandwidth</p>
</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228164008242.png" alt="image-20231228164008242"></p>
<h4 id="LogP模型"><a href="#LogP模型" class="headerlink" title="LogP模型"></a>LogP模型</h4><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5><p>由Culler(1993)年提出的，是一种分布存储的、点到点通讯的多处理机模型，其中通讯由一组参数描述，实行隐式同步。</p>
<p><strong>模型参数：</strong></p>
<ul>
<li>L(Latency) 表示源处理机与目的处理机进行消息（一个或几个字）通信所需要的等待或延迟时间的上限，表示网络中消息的延迟。</li>
<li>o(overhead)表示处理机准备发送或接收每个消息的时间开销（包括操作系统核心开销和网络软件开销），在这段时间里处理不能执行其它操作。</li>
<li>g(gap)表示一台处理机连续两次发送或接收消息时的最小时间间隔，其倒数即微处理机的通信带宽。</li>
<li>P(Processor)处理机&#x2F;存储器模块个数</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228165212076.png" alt="image-20231228165212076"></p>
<p>注：<em>L</em>和<em>g</em>反映了通讯网络的容量</p>
<h3 id="性能评测"><a href="#性能评测" class="headerlink" title="性能评测"></a>性能评测</h3><blockquote>
<p>性能评测：性能评价和性能分析</p>
<p>• 性能评价和性能分析可以揭示高性能计算机、并行算法和并行应用程序的性能特点和性能瓶颈，指导高性能计算机、并行算法和应用程序的设计与改进</p>
</blockquote>
<h4 id="机器级性能评测"><a href="#机器级性能评测" class="headerlink" title="机器级性能评测"></a>机器级性能评测</h4><blockquote>
<p>CPU和存储器的某些基本性能指标；并行和通信开销分析；并行机的可用性与好用性以及机器成本、价格与性&#x2F;价比</p>
</blockquote>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228172728623.png" alt="image-20231228172728623" style="zoom:80%;" />

<h4 id="算法级性能评测"><a href="#算法级性能评测" class="headerlink" title="算法级性能评测"></a>算法级性能评测</h4><ul>
<li><strong>加速比（Speedup）</strong>：对于一个给定的应用，并行算法（或并行程序）相对于串行算法（或串行程序）的性能提高程度。<ul>
<li>Amdahl定律</li>
<li>Gustafson定律</li>
<li>Sun Ni定律</li>
</ul>
</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228173545233.png" alt="image-20231228173545233"></p>
<ul>
<li><strong>可扩展性（Scalability）</strong>：当系统和问题的规模增大时，可维持相同性能的能力，即指应用、算法和结构能否充分利用不断增长的处理器的能力<ul>
<li>等效率度量标准</li>
<li>等速度度量标准</li>
<li>平均延迟度量标准</li>
</ul>
</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228173558266.png" alt="image-20231228173558266"></p>
<h5 id="Amdahl定律"><a href="#Amdahl定律" class="headerlink" title="Amdahl定律"></a>Amdahl定律</h5><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228175033604.png" alt="image-20231228175033604" style="zoom: 80%;" />

<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228175459022.png" alt="image-20231228175459022" style="zoom:80%;" />

<p><strong>增强的Amdahl定律</strong></p>
<img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228175550576.png" alt="image-20231228175550576" style="zoom:80%;" />



<h5 id="Gustafson定律"><a href="#Gustafson定律" class="headerlink" title="Gustafson定律"></a>Gustafson定律</h5><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231228210658231.png" alt="image-20231228210658231"></p>
<h5 id="Sun-Ni定律"><a href="#Sun-Ni定律" class="headerlink" title="Sun &amp; Ni定律"></a>Sun &amp; Ni定律</h5><h4 id="程序级性能评测"><a href="#程序级性能评测" class="headerlink" title="程序级性能评测"></a>程序级性能评测</h4><h5 id="等效率测速（Efficiency-Metrics）"><a href="#等效率测速（Efficiency-Metrics）" class="headerlink" title="等效率测速（Efficiency Metrics）"></a>等效率测速（Efficiency Metrics）</h5><ul>
<li>效率：加速比 &#x2F; 处理器数</li>
<li>简单情况下能得出分析结果</li>
</ul>
<h2 id="并行算法设计"><a href="#并行算法设计" class="headerlink" title="并行算法设计"></a>并行算法设计</h2><p>…</p>
<blockquote>
<p> PCAM设计方法学，并行算法的一般设计过程</p>
</blockquote>
<p>设计并行算法的四个阶段</p>
<ul>
<li>划分（Partitioning）</li>
<li>通信（Communication）</li>
<li>组合（Agglomeration）</li>
<li>映射（Mapping）</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231230164316589.png" alt="image-20231230164316589"></p>
<h3 id="划分"><a href="#划分" class="headerlink" title="划分"></a>划分</h3><p>划分方法描述</p>
<p>充分开拓算法的并发性和可扩放性；</p>
<p>分为两类划分：</p>
<ul>
<li><p>域分解(domain decomposition)&#x2F;数据分解</p>
</li>
<li><p>功能分解(functional decomposition)</p>
</li>
</ul>
<p>• 先进行数据分解(称域分解)，再进行计算功能的分解(称功能分解)； </p>
<p>• 使数据集和计算集互不相交</p>
<p>• 划分阶段忽略处理器数目和目标机器的体系结构</p>
<h4 id="域划分"><a href="#域划分" class="headerlink" title="域划分"></a>域划分</h4><ul>
<li><p>划分的<strong>对象是数据</strong>，可以是算法的输入数据、中间处理数据和输出数据</p>
</li>
<li><p>将数据分解成大致相等的小数据片</p>
</li>
<li><p>划分时考虑数据上的相应操作</p>
</li>
<li><p>如果一个任务需要别的任务中的数据，则会产生任务间的通信</p>
</li>
</ul>
<h4 id="功能划分"><a href="#功能划分" class="headerlink" title="功能划分"></a>功能划分</h4><ul>
<li><p>划分的<strong>对象是计算</strong>，将计算划分为不同的任务，其出发点不同于域分解；</p>
</li>
<li><p>划分后，研究不同任务所需的数据。</p>
<ul>
<li><p>如果这些数据不相交的，则划分是成功的；</p>
</li>
<li><p>如果数据有相当的重叠， 意味着要重新进行域分解和功能分解；</p>
</li>
</ul>
</li>
<li><p>功能分解是一种更深层次的分解。</p>
</li>
</ul>
<h3 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h3><ul>
<li><p>通信是PCAM设计过程的重要阶段；</p>
</li>
<li><p>划分产生的诸任务，一般不能完全独立执行，需要在任务间进行数据交流；从而产生了通信；</p>
</li>
<li><p>功能分解确定了诸任务之间的数据流；</p>
</li>
<li><p>诸任务是并发执行的，通信则限制了这种并发性；</p>
</li>
</ul>
<h4 id="四种通信模式"><a href="#四种通信模式" class="headerlink" title="四种通信模式"></a>四种通信模式</h4><ul>
<li>局部&#x2F;全局通信（Local&#x2F;Global communication）</li>
<li>结构化&#x2F;非结构化通信（Structure&#x2F;Unstructured communication）</li>
<li>静态&#x2F;动态通信（Static&#x2F;Dynamic communication）</li>
<li>同步&#x2F;异步通信（Synchonous&#x2F;Asynchronous）</li>
</ul>
<h3 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h3><ul>
<li><p>组合是由抽象到具体的过程，是使得组合的任务能在一类并行机上有效的执行</p>
</li>
<li><p>合并小尺寸任务，减少任务数。如果任务数恰好等于处理器数，则也完成了映射过程</p>
</li>
<li><p>通过增加任务的粒度和重复计算，可以减少通信成本</p>
</li>
<li><p>保持映射和扩展的灵活性，降低软件工程成本</p>
</li>
</ul>
<h4 id="表面-容积效应（Surface-to-Volume-Effects）"><a href="#表面-容积效应（Surface-to-Volume-Effects）" class="headerlink" title="表面-容积效应（Surface-to-Volume Effects）"></a>表面-容积效应（Surface-to-Volume Effects）</h4><ul>
<li>通信量与任务子集的表面成正比，计算量与任务子集的体积成正比</li>
<li>增加重复计算有可能减少通讯量</li>
</ul>
<h3 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h3><ul>
<li><p>每个任务要映射到具体的处理器，定位到运行机器上；</p>
</li>
<li><p>任务数大于处理器数时，存在负载平衡和任务调度问题；</p>
</li>
<li><p>映射的目标：减少算法的执行时间</p>
<ul>
<li><p>并发的任务 -&gt; 不同的处理器</p>
</li>
<li><p>任务之间存在高通信的 -&gt; 同一处理器</p>
</li>
</ul>
</li>
</ul>
<p>• 映射实际是一种权衡，属于NP完全问题；</p>
<h4 id="两种策略"><a href="#两种策略" class="headerlink" title="两种策略"></a>两种策略</h4><ul>
<li><p>使得任务可以被不同的处理器并发地执行，增强并发性（concurrency） </p>
</li>
<li><p>将通信频繁的任务放到同一个处理器上，增强局部性 （locality）</p>
</li>
</ul>
<h4 id="负载平衡算法"><a href="#负载平衡算法" class="headerlink" title="负载平衡算法"></a>负载平衡算法</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="C:\Users\胡华裕\AppData\Roaming\Typora\typora-user-images\image-20231230180721598.png" alt="image-20231230180721598"></p>
<h4 id="任务调度算法"><a href="#任务调度算法" class="headerlink" title="任务调度算法"></a>任务调度算法</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20231230180823162.png" alt="image-20231230180823162"></p>
<h2 id="并行程序设计基础"><a href="#并行程序设计基础" class="headerlink" title="并行程序设计基础"></a>并行程序设计基础</h2><h3 id="Cannon"><a href="#Cannon" class="headerlink" title="Cannon"></a>Cannon</h3><h4 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20240102203817028.png" alt="image-20240102203817028"></p>
<h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/image-20240102203925846.png" alt="image-20240102203925846"></p>
<h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><h2 id="OpenMP"><a href="#OpenMP" class="headerlink" title="OpenMP"></a>OpenMP</h2><p><strong>进程：</strong> 进程是操作系统资源分配的基本实体<br><strong>线程：</strong> 线程是CPU调度和分配的基本单位<br>在Linux系统下是没有线程的概念的，它是用进程模拟的线程，因此把线程叫做轻量级进程。</p>
<blockquote>
<p>OpenMP 是一个应用程序接口(API)，由一组主要的计算机硬件和软件供应商联合定义。OpenMP 为共享内存并行应用程序的开发人员提供了一个可移植的、可伸缩的模型。该API在多种体系结构上支持 C&#x2F;C++ 和 Fortran。</p>
</blockquote>
<h3 id="什么是OpenMP"><a href="#什么是OpenMP" class="headerlink" title="什么是OpenMP"></a>什么是OpenMP</h3><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9931c05f4058">OpenMP中文教程 - 简书 (jianshu.com)</a></p>
<p><strong>OpenMP是：</strong></p>
<ul>
<li>一种应用程序接口(API)，可用于显式地指示多线程、<strong>共享内存</strong>并行性。</li>
<li>由三个主要的API组件组成：<ul>
<li>编译器指令</li>
<li>运行时库函数</li>
<li>环境变量</li>
</ul>
</li>
<li>Open Multi-Processing的缩写</li>
</ul>
<h3 id="Fork-Join模型"><a href="#Fork-Join模型" class="headerlink" title="Fork-Join模型"></a><code>Fork-Join</code>模型</h3><ul>
<li>OpenMP 使用并行执行的 fork-join 模型：</li>
</ul>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="https://www.hz-bin.cn/assets/images/fork_join2.gif" alt="img"></p>
<ul>
<li>所有 OpenMP 程序都开始于一个主线程。主线程按顺序执行，直到遇到第一个并行区域结构。</li>
<li><strong>FORK</strong>：主线程然后创建一组并行线程。</li>
<li>之后程序中由并行区域结构封装的语句在各个团队线程中并行执行。</li>
<li><strong>JOIN</strong>：当团队线程完成并行区域结构中的语句时，它们将进行同步并终止，只留下主线程。</li>
<li>并行区域的数量和组成它们的线程是任意的。</li>
</ul>
<h3 id="编译器指令"><a href="#编译器指令" class="headerlink" title="编译器指令"></a>编译器指令</h3><h4 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h4><table>
<thead>
<tr>
<th>#pragma omp</th>
<th>directive-name</th>
<th>[clause, …]</th>
<th>newline</th>
</tr>
</thead>
<tbody><tr>
<td>所有 OpenMP C&#x2F;C++ 指令都需要。</td>
<td>一个有效的 OpenMP 指令。必须出现在 <code>pragma</code> 之后和任何子句之前。</td>
<td>可选的。除非另有限制，子句可以按任何顺序重复。</td>
<td>必需的。在此指令所包含的结构化块之前。</td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp 指令 [子句]</span></span><br></pre></td></tr></table></figure>

<p><strong>下面是一些常见的OpenMP编译器指令格式的示例：</strong></p>
<ol>
<li><code>#pragma omp parallel</code>：用于创建并行区域，指示编译器将其中的代码并行执行，并创建一个线程团队。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp parallel [clause]</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 并行执行的代码块</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><code>#pragma omp for</code>：用于并行化循环，将循环迭代分配给不同的线程执行。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp for [clause]</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="comment">// 循环体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>循环增量操作：循环增量操作会由编译器自动处理，保证每个线程独立地更新自己的循环变量。</li>
<li>如果循环体内部存在对共享变量的修改操作，可能会导致竞争条件。在这种情况下，需要使用适当的同步机制</li>
</ul>
<ol>
<li><code>#pragma omp critical</code>：用于标记一个临界区，保证在任意时刻只有一个线程可以进入该临界区。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp critical</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 临界区代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><code>#pragma omp barrier</code>：用于插入一个隐式的同步点，确保所有线程在此处等待，直到所有线程都到达该点。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp barrier</span></span><br></pre></td></tr></table></figure>

<ol>
<li><code>#pragma omp parallel for</code>：结合了并行区域和循环并行化的指令，用于并行化循环并创建线程团队。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> omp parallel for [clause]</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    <span class="comment">// 循环体</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>常用的子句如下：</strong></p>
<ul>
<li>num_threads(num)：指定并行域内线程的数目；</li>
<li>shared(var1,var2)：指定一个或者多个变量为多个线程的共享变量；</li>
<li>private(var1,var2)：指定一个变量或者多个变量在每个线程中都有它的副本；　</li>
<li>reduction(operator:product):指定归约操作。该子句用于指定在并行循环中进行归约操作的变量，并指定归约操作的类型，如求和、求积、求最大值等。（变量同名）（并行区里的变量是私有的）</li>
</ul>
<h3 id="运行时库函数"><a href="#运行时库函数" class="headerlink" title="运行时库函数"></a>运行时库函数</h3><p><strong>下面是一些常用的OpenMP函数：</strong></p>
<p>omp_get_thread_num()：返回当前线程的线程号。</p>
<p>omp_get_num_threads()：返回并行区域中的线程数。</p>
<p>omp_set_num_threads(int num_threads)：设置并行区域中的线程数。</p>
<p>omp_get_max_threads()：返回可用的最大线程数。</p>
<p>omp_get_wtime()：返回当前时间，用于计算程序的执行时间。</p>
<p>omp_get_num_procs()：返回系统中的处理器核心数。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">long</span> num_threads=<span class="number">128</span>;</span><br><span class="line"><span class="type">long</span> num_steps=<span class="number">100000000</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">double</span> sum,pi;</span><br><span class="line">    <span class="type">double</span> step = <span class="number">1</span>/(<span class="type">double</span>)num_steps;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=num_threads;i++)&#123;</span><br><span class="line">        <span class="type">double</span> start = <span class="built_in">omp_get_wtime</span>();</span><br><span class="line">        sum=<span class="number">0.0</span>;</span><br><span class="line">        pi=<span class="number">0.0</span>;</span><br><span class="line">        <span class="type">double</span> x;</span><br><span class="line">        <span class="meta">#<span class="keyword">pragma</span> omp parallel for num_threads(i) private(x) reduction(+:sum)</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;num_steps;j++)&#123;</span><br><span class="line">            x=step*(j+<span class="number">0.5</span>);</span><br><span class="line">            sum+=<span class="number">4</span>/(<span class="number">1</span>+ x*x);</span><br><span class="line">        &#125;</span><br><span class="line">        pi=sum*step;</span><br><span class="line">        cout&lt;&lt;pi&lt;&lt;<span class="string">&quot;   time=&quot;</span>&lt;&lt;<span class="built_in">omp_get_wtime</span>()-start&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><h2 id="MPI"><a href="#MPI" class="headerlink" title="MPI"></a>MPI</h2><h3 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h3><blockquote>
<p>MPI 全名叫 Message Passing Interface，即信息传递接口，作用是可以通过 MPI 可以在不同进程间传递消息，从而可以并行地处理任务，即进行并行计算。需要注意的是，尽管我们偶尔会说使用 MPI 编写了某某可执行程序，但是 MPI 其实只是一个库，而不是一种语言，其可以被 Fortran、C、C++、Python 调用。</p>
</blockquote>
<p>​	MPI并不是多线程编程模型，而是多进程编程模型。它强调进程间的消息传递和同步，而不是共享内存。因此，MPI适用于分布式内存系统（如集群）上的并行计算，而不适用于共享内存系统（如多核处理器）上的并行计算。</p>
<h4 id="通讯域"><a href="#通讯域" class="headerlink" title="通讯域"></a>通讯域</h4><p>通信域定义了一组能够互相发消息的进程。在这组进程中，每个进程会被分配一个序号，称为 rank，进程间显性地通过指定 rank 作为标识来进行通信，一个进程 rank 可以指定另一个进程的 rank 以及独一无二的消息标签 tag 来发送消息。接收者也可以发送一个特定标签标记的消息的请求。类似于这样的涉及一个发送者以及一个接收者的通信被称为点对点(point-to-point)通信。</p>
<h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><p><code>MPI_Init</code>是MPI库中的一个函数，它用于初始化MPI运行环境。在一个MPI程序中，通常在主函数的开始处调用<code>MPI_Init</code>函数。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="type">int</span> *argc, <span class="type">char</span> ***argv)</span></span></span><br></pre></td></tr></table></figure>

<p>参数<code>argc</code>和<code>argv</code>是主函数的参数，它们是用于命令行参数传递的。在调用<code>MPI_Init</code>之后，MPI库会解析并处理这些参数，并从中提取MPI相关的信息。这样做是为了确保MPI库能够正确地获取运行MPI程序所需的全部资源。</p>
<p>调用<code>MPI_Init</code>后，MPI运行环境会被初始化，MPI库将为每个MPI进程分配必要的资源，并建立MPI进程间的通信通道。每个进程都会被分配一个唯一的标识符（rank），可以通过调用<code>MPI_Comm_rank</code>函数获取自己的rank值。</p>
<hr>
<p><strong>MPI_COMM_WORLD:</strong></p>
<p>MPI_COMM_WORLD是MPI中的一个预定义的通信器（communicator）。它表示一个包含所有MPI进程的通信组，也就是所有进程之间的默认通信环境。</p>
<p>在MPI程序中，通信器（communicator）是一个抽象的概念，用于指定一组进程之间的通信关系。通信器定义了一个进程组，进程组中的进程可以相互通信。MPI提供了多种创建和使用通信器的方法，其中MPI_COMM_WORLD是最常用的一个。</p>
<p>MPI_COMM_WORLD通信器由MPI库在程序启动时自动创建，并且包含了运行MPI程序的所有进程。它是一个全局的通信器，可以在程序中直接使用，无需显式创建或销毁。在MPI函数中，通过指定MPI_COMM_WORLD作为通信器参数，可以将操作应用于所有进程之间的通信。</p>
<hr>
<p><code>MPI_Comm_rank</code>是MPI库中的一个函数，用于获取当前进程在指定通信器中的标识符（rank）。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="type">int</span> *rank)</span></span></span><br></pre></td></tr></table></figure>

<p>参数<code>comm</code>是一个MPI通信器，用于指定进程组的通信关系。通常可以使用<code>MPI_COMM_WORLD</code>作为通信器，表示全局的通信组。参数<code>rank</code>是一个指向整数的指针，用于存储当前进程在指定通信器中的rank值。</p>
<p>调用<code>MPI_Comm_rank</code>函数后，当前进程会获取指定通信器中的rank值，并将其存储在<code>rank</code>指向的变量中。rank值从0开始，表示进程在通信组中的唯一标识符。</p>
<hr>
<p><code>MPI_Comm_size</code>是MPI库中的一个函数，用于获取指定通信器中的进程总数。</p>
<p>函数原型如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int MPI_Comm_size(MPI_Comm comm, int *size)</span><br></pre></td></tr></table></figure>

<p>参数<code>comm</code>是一个MPI通信器，用于指定进程组的通信关系。通常可以使用<code>MPI_COMM_WORLD</code>作为通信器，表示全局的通信组。参数<code>size</code>是一个指向整数的指针，用于存储指定通信器中的进程总数。</p>
<p>调用<code>MPI_Comm_size</code>函数后，当前进程会获取指定通信器中的进程总数，并将其存储在<code>size</code>指向的变量中。</p>
<hr>
<p><code>MPI_Reduce</code>是MPI库中的一个函数，用于在通信组中进行归约操作（reduce）。归约操作将多个进程的数据进行聚合，得到一个全局的结果。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Reduce</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *sendbuf, <span class="type">void</span> *recvbuf, <span class="type">int</span> count, MPI_Datatype datatype, MPI_Op op, <span class="type">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>sendbuf</code>：发送缓冲区的起始地址，指定了每个进程要发送的数据。</li>
<li><code>recvbuf</code>：接收缓冲区的起始地址，用于存储归约操作的结果。只在根进程（root）中有效。</li>
<li><code>count</code>：发送和接收缓冲区中的元素数量。</li>
<li><code>datatype</code>：数据元素的类型。</li>
<li><code>op</code>：归约操作的类型，例如<code>MPI_SUM</code>表示求和操作。</li>
<li><code>root</code>：根进程的rank值，指定了接收归约结果的进程。</li>
<li><code>comm</code>：通信器，用于指定通信组。</li>
</ul>
<p>调用<code>MPI_Reduce</code>函数后，在通信组中的每个进程将把自己的数据（位于<code>sendbuf</code>中）根据指定的归约操作（<code>op</code>）进行归约，最终的结果将存储在根进程的<code>recvbuf</code>中。</p>
<hr>
<p><code>MPI_Finalize</code>是MPI库中的一个函数，用于结束MPI运行环境，释放相关资源。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Finalize</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<p>调用<code>MPI_Finalize</code>函数会终止当前MPI程序的执行，并释放与MPI相关的资源。通常，<code>MPI_Finalize</code>应该在主函数的结尾处被调用。</p>
<hr>
<p><code>MPI_Send</code>是MPI库中的一个函数，用于发送消息（数据）给其他进程。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Send</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *buf, <span class="type">int</span> count, MPI_Datatype datatype, <span class="type">int</span> dest, <span class="type">int</span> tag, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>buf</code>：发送缓冲区的起始地址，指定了要发送的数据。</li>
<li><code>count</code>：发送缓冲区中的元素数量。</li>
<li><code>datatype</code>：数据元素的类型。</li>
<li><code>dest</code>：目标进程的rank值，指定了消息的接收进程。</li>
<li><code>tag</code>：消息的标签，用于区分不同的消息。</li>
<li><code>comm</code>：通信器，用于指定通信组。</li>
</ul>
<hr>
<p><code>MPI_Recv</code>是MPI库中的一个函数，用于接收其他进程发送的消息（数据）。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Recv</span><span class="params">(<span class="type">void</span> *buf, <span class="type">int</span> count, MPI_Datatype datatype, <span class="type">int</span> source, <span class="type">int</span> tag, MPI_Comm comm, MPI_Status *status)</span></span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>buf</code>：接收缓冲区的起始地址，用于存储接收到的数据。</li>
<li><code>count</code>：接收缓冲区中的元素数量。</li>
<li><code>datatype</code>：数据元素的类型。</li>
<li><code>source</code>：源进程的rank值，指定了消息的发送进程。</li>
<li><code>tag</code>：消息的标签，用于区分不同的消息。</li>
<li><code>comm</code>：通信器，用于指定通信组。</li>
<li><code>status</code>：用于返回接收操作的状态信息。</li>
</ul>
<hr>
<p><code>MPI_Bcast</code>是MPI库中的一个函数，用于将数据广播给所有进程，使得每个进程都能接收到相同的数据。</p>
<p>函数原型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MPI_Bcast</span><span class="params">(<span class="type">void</span> *buffer, <span class="type">int</span> count, MPI_Datatype datatype, <span class="type">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>buffer</code>：发送缓冲区的起始地址（对于根进程）或接收缓冲区的起始地址（对于非根进程）。</li>
<li><code>count</code>：缓冲区中的元素数量。</li>
<li><code>datatype</code>：数据元素的类型。</li>
<li><code>root</code>：广播操作的根进程的rank值，即广播操作的发送方。</li>
<li><code>comm</code>：通信器，用于指定通信组。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> rank,size;</span><br><span class="line">    <span class="type">int</span> n = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">MPI_Init</span>(&amp;argc,&amp;argv); <span class="comment">// 初始化MPI环境，创建MPI_COMM_WORLD</span></span><br><span class="line">    <span class="built_in">MPI_Comm_rank</span>(MPI_COMM_WORLD,&amp;rank); <span class="comment">// 获取当前进程在指定通信器中的标识符</span></span><br><span class="line">    <span class="built_in">MPI_Comm_size</span>(MPI_COMM_WORLD,&amp;size); <span class="comment">// 获取指定通信器中的进程总数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(rank == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">MPI_Send</span>(&amp;rank,<span class="number">1</span>,MPI_INT,<span class="number">1</span>,<span class="number">0</span>,MPI_COMM_WORLD); <span class="comment">// 发送数据</span></span><br><span class="line">        cin&gt;&gt;n;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">MPI_Bcast</span>(&amp;n,<span class="number">1</span>,MPI_INT,<span class="number">0</span>,MPI_COMM_WORLD); <span class="comment">// 广播，对于0是发，非0是收</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="type">int</span> t=<span class="number">-1</span>;</span><br><span class="line">        MPI_Status status;</span><br><span class="line">        <span class="built_in">MPI_Recv</span>(&amp;t,<span class="number">1</span>,MPI_INT,<span class="number">0</span>,<span class="number">0</span>,MPI_COMM_WORLD,&amp;status); <span class="comment">// 接收数据</span></span><br><span class="line">        <span class="comment">//cout&lt;&lt;t&lt;&lt;endl;</span></span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;n&lt;&lt;endl;</span><br><span class="line">    <span class="built_in">MPI_Finalize</span>(); <span class="comment">// 结束MPI环境，释放资源</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> *argv[])</span></span>&#123;</span><br><span class="line">    <span class="type">long</span> num_steps; <span class="comment">// 步数</span></span><br><span class="line">    <span class="type">double</span> step; <span class="comment">// 步长</span></span><br><span class="line">    <span class="type">double</span> sum=<span class="number">0.0</span>,x; </span><br><span class="line">    <span class="type">double</span> pi;</span><br><span class="line">    <span class="type">int</span> rank;</span><br><span class="line">    <span class="type">int</span> size;</span><br><span class="line">    <span class="built_in">MPI_Init</span>(&amp;argc,&amp;argv); <span class="comment">// 初始化MPI环境</span></span><br><span class="line">    <span class="built_in">MPI_Comm_rank</span>(MPI_COMM_WORLD,&amp;rank); <span class="comment">// 获取进程标识</span></span><br><span class="line">    <span class="built_in">MPI_Comm_size</span>(MPI_COMM_WORLD,&amp;size); <span class="comment">// 获取进程数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;请输入步数：&quot;</span>&lt;&lt;endl;</span><br><span class="line">        cin&gt;&gt;num_steps;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MPI_Bcast</span>(&amp;num_steps,<span class="number">1</span>,MPI_LONG,<span class="number">0</span>,MPI_COMM_WORLD); <span class="comment">// 广播</span></span><br><span class="line">    step = <span class="number">1</span>/(<span class="type">double</span>)num_steps;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=rank;i&lt;num_steps;i+=size)&#123;</span><br><span class="line">        x=step*(i+<span class="number">0.5</span>);</span><br><span class="line">        sum+=<span class="number">4</span>/(<span class="number">1</span>+x*x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MPI_Reduce</span>(&amp;sum,&amp;pi,<span class="number">1</span>,MPI_DOUBLE,MPI_SUM,<span class="number">0</span>,MPI_COMM_WORLD); <span class="comment">// 归约</span></span><br><span class="line">    <span class="keyword">if</span>(rank==<span class="number">0</span>)&#123;</span><br><span class="line">        pi = pi*step;</span><br><span class="line">        cout&lt;&lt;pi&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MPI_Finalize</span>(); <span class="comment">// 结束MPI环境</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="Hadoop-and-MapReduce"><a href="#Hadoop-and-MapReduce" class="headerlink" title="Hadoop and MapReduce"></a>Hadoop and MapReduce</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54994736">深入浅出大数据：到底什么是Hadoop？ - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/7143767067907325982">https://juejin.cn/post/7143767067907325982</a></p>
<h3 id="Hadoop是什么？"><a href="#Hadoop是什么？" class="headerlink" title="Hadoop是什么？"></a>Hadoop是什么？</h3><p>1）Hadoop是一个由Apache基金会所开发的<strong>分布式系统基础架构</strong>。 </p>
<p>2）主要解决，<strong>海量数据的存储</strong>和<strong>海量数据的分析计算</strong>问题。 </p>
<p>3）广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。</p>
<h3 id="Hadoop特点"><a href="#Hadoop特点" class="headerlink" title="Hadoop特点"></a>Hadoop特点</h3><h4 id="高可靠性"><a href="#高可靠性" class="headerlink" title="高可靠性"></a>高可靠性</h4><p>Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。</p>
<h4 id="高扩展性"><a href="#高扩展性" class="headerlink" title="高扩展性"></a>高扩展性</h4><p>在集群间分配任务数据，可方便的扩展数以千计的节点。</p>
<h4 id="高效性"><a href="#高效性" class="headerlink" title="高效性"></a>高效性</h4><p>在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p>
<h4 id="高容错性"><a href="#高容错性" class="headerlink" title="高容错性"></a>高容错性</h4><p>能够自动将失败的任务重新分配。</p>
<h3 id="Hadoop组成"><a href="#Hadoop组成" class="headerlink" title="Hadoop组成"></a>Hadoop组成</h3><h4 id="Hadoop1-x、2-x、3-x区别"><a href="#Hadoop1-x、2-x、3-x区别" class="headerlink" title="Hadoop1.x、2.x、3.x区别"></a>Hadoop1.x、2.x、3.x区别</h4><p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/695c3229db4c4c4b872a6d5733d51115~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="在这里插入图片描述"></p>
<h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。</p>
<p>1）<strong>NameNode（nn）</strong>：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。 </p>
<p>2）**DataNode(dn)**：在本地文件系统存储文件块数据，以及块数据的校验和。 </p>
<p>3）**Secondary NameNode(2nn)**：每隔一段时间对NameNode元数据备份。。</p>
<h4 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h4><p>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop 的资源管理器。</p>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/be21fc58865e4b99b7367ea964e9ca0e~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="在这里插入图片描述"></p>
<h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><p>MapReduce将计算过程分为两个阶段：Map和Reduce </p>
<p>1）Map阶段并行处理输入数据 </p>
<p>2）Reduce阶段对Map结果进行汇总</p>
<p><img src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/00a793fbdfc1415597042ee79d305ca7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="在这里插入图片描述"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.creaational;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.*;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object,Text,Text,IntWritable&gt;&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key,Text value,Context context)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">tks</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">            <span class="keyword">while</span>(tks.hasMoreTokens())&#123;</span><br><span class="line">                word.set(tks.nextToken());</span><br><span class="line">                context.write(word,one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text,IntWritable,Text,IntWritable&gt;&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key,Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(IntWritable val : values)&#123;</span><br><span class="line">                sum += val.get();</span><br><span class="line">            &#125;</span><br><span class="line">            result.set(sum);</span><br><span class="line">            context.write(key,result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Job</span>。getInstance(conf,<span class="string">&quot;word count&quot;</span>);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">        job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">        job.setReduceClass(IntSumReducer.class);</span><br><span class="line"></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.addInputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitComplete(<span class="literal">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Container-and-Docker"><a href="#Container-and-Docker" class="headerlink" title="Container and Docker"></a>Container and Docker</h2><ul>
<li>制定容器镜像格式</li>
<li>构建容器镜像 <code>docker build</code></li>
<li>管理容器镜像 <code>docker images</code></li>
<li>管理容器实例 <code>docker ps</code></li>
<li>运行容器 <code>docker run</code></li>
<li>实现容器镜像共享 <code>docker pull/push</code></li>
</ul>
<p><code>docker ps</code>:查看容器实例</p>
<p><code>docker stats</code>:查看容器资源使用情况</p>
<h3 id="Docker-commands"><a href="#Docker-commands" class="headerlink" title="Docker commands"></a>Docker commands</h3><table>
<thead>
<tr>
<th>Command</th>
<th>Note</th>
</tr>
</thead>
<tbody><tr>
<td>docker network ls</td>
<td>列出当前Docker主机上的所有网络</td>
</tr>
<tr>
<td>docker network inspect NETWORK_ID</td>
<td>检查Docker网络的详细详细信息</td>
</tr>
<tr>
<td>docker exec CONTAINED_NAME cat &#x2F;etc&#x2F;host</td>
<td>查看指定容器中，文件内容</td>
</tr>
<tr>
<td>docker exec -it CONTATNED_NAME &#x2F;bin&#x2F;bash</td>
<td>打开交互式的Bash shell</td>
</tr>
<tr>
<td>docker logs –details CONTAINTED_NAME</td>
<td>查看容器的日志信息</td>
</tr>
</tbody></table>
<ul>
<li></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.hu1hu.top">hu1hu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.hu1hu.top/posts/idek234jld/">https://www.hu1hu.top/posts/idek234jld/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.hu1hu.top" target="_blank">My学习之路</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%AB%98%E6%80%A7%E8%83%BD%E4%BA%91%E8%AE%A1%E7%AE%97/">高性能云计算</a></div><div class="post_share"><div class="social-share" data-image="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/R.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="/img/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="/img/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/jdis324/" title="MySQL"><img class="cover" src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/mysql-logo.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MySQL</div></div></a></div><div class="next-post pull-right"><a href="/posts/ishdl67348h/" title="软件工程复习"><img class="cover" src="https://img.zcool.cn/community/01b3d35a3b5fb2a801201a1fe7fc92.gif" data-original="http://hu1hu-markdown.oss-cn-heyuan.aliyuncs.com/images/软件工程.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">软件工程复习</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">并行计算概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">什么是并行计算？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%9D%A1%E4%BB%B6"><span class="toc-number">1.2.</span> <span class="toc-text">基本条件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E7%9B%AE%E6%A0%87"><span class="toc-number">1.3.</span> <span class="toc-text">主要目标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%EF%BC%881%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">并行计算体系结构（1）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87"><span class="toc-number">2.1.1.</span> <span class="toc-text">并行计算机网络性能指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%99%E6%80%81%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%9C"><span class="toc-number">2.2.</span> <span class="toc-text">静态互联网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%99%E6%80%81%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.2.1.</span> <span class="toc-text">静态连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E7%BB%B4%E7%BA%BF%E6%80%A7%E9%98%B5%E5%88%97"><span class="toc-number">2.2.2.</span> <span class="toc-text">一维线性阵列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E7%BD%91%E5%AD%94"><span class="toc-number">2.2.3.</span> <span class="toc-text">二维网孔</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E5%8F%89%E6%A0%91"><span class="toc-number">2.2.4.</span> <span class="toc-text">二叉树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B6%85%E7%AB%8B%E6%96%B9"><span class="toc-number">2.2.5.</span> <span class="toc-text">超立方</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#k-%E7%AB%8B%E6%96%B9%E7%8E%AF"><span class="toc-number">2.2.6.</span> <span class="toc-text">k-立方环</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%99%E6%80%81%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%9C%E7%89%B9%E6%80%A7%E6%AF%94%E8%BE%83%EF%BC%88%E8%AE%B0%EF%BC%89"><span class="toc-number">2.2.7.</span> <span class="toc-text">静态互联网络特性比较（记）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E4%BA%92%E8%81%94%E7%BD%91%E7%BB%9C"><span class="toc-number">2.3.</span> <span class="toc-text">动态互联网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%EF%BC%882%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">并行计算体系结构（2）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Flynn%E5%88%86%E7%B1%BB"><span class="toc-number">3.1.</span> <span class="toc-text">Flynn分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">内存访问模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-number">3.2.1.</span> <span class="toc-text">并行计算机的体系结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98vs%E5%88%86%E5%B8%83%E5%BC%8F%E5%86%85%E5%AD%98"><span class="toc-number">3.2.2.</span> <span class="toc-text">共享内存vs分布式内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-number">3.2.3.</span> <span class="toc-text">共享内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%86%85%E5%AD%98"><span class="toc-number">3.2.4.</span> <span class="toc-text">分布式内存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.5.</span> <span class="toc-text">并行计算机访问模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UMA%EF%BC%88Uniform-Memory-Access%EF%BC%89"><span class="toc-number">3.2.6.</span> <span class="toc-text">UMA（Uniform Memory Access）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NUMA%EF%BC%88Non-Uniform-Memory-Access%EF%BC%89"><span class="toc-number">3.2.7.</span> <span class="toc-text">NUMA（Non-Uniform Memory Access）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CC-NUMA%EF%BC%88%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%9D%9E%E5%9D%87%E5%8C%80%E5%AD%98%E5%82%A8%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">3.2.8.</span> <span class="toc-text">CC-NUMA（高速缓存一致性非均匀存储访问模型）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#COMA"><span class="toc-number">3.2.9.</span> <span class="toc-text">COMA</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NORMA-%EF%BC%88%E9%9D%9E%E8%BF%9C%E7%A8%8B%E5%AD%98%E5%82%A8%E8%AE%BF%E9%97%AE%EF%BC%89"><span class="toc-number">3.2.10.</span> <span class="toc-text">(NORMA)（非远程存储访问）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PVP%EF%BC%88Parallel-Vector-Processor%EF%BC%89"><span class="toc-number">3.2.11.</span> <span class="toc-text">PVP（Parallel Vector Processor）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SMP%EF%BC%88Symmetric-Multiprocessing%EF%BC%89"><span class="toc-number">3.2.12.</span> <span class="toc-text">SMP（Symmetric Multiprocessing）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86%E6%9C%BA%EF%BC%88Massively-Parallel-Processor%EF%BC%8CMPP%EF%BC%89"><span class="toc-number">3.2.13.</span> <span class="toc-text">大规模并行处理机（Massively Parallel Processor，MPP）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E3%80%81%E6%9C%BA%E7%BE%A4%EF%BC%88Cluster%EF%BC%89-COW"><span class="toc-number">3.2.14.</span> <span class="toc-text">集群、机群（Cluster）&#x2F;COW</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MPP-vs-Cluster"><span class="toc-number">3.2.15.</span> <span class="toc-text">MPP vs Cluster</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DSM%EF%BC%88Distributed-Shared-Memory-%EF%BC%8CDSM%EF%BC%89"><span class="toc-number">3.2.16.</span> <span class="toc-text">DSM（Distributed Shared Memory ，DSM）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%BD%93%E7%B3%BB"><span class="toc-number">3.2.17.</span> <span class="toc-text">内存体系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E7%A7%8D%E7%BB%93%E6%9E%84%E7%89%B9%E6%80%A7"><span class="toc-number">3.2.18.</span> <span class="toc-text">五种结构特性</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B%E5%8F%8A%E6%80%A7%E8%83%BD%E8%AF%84%E6%B5%8B"><span class="toc-number">4.</span> <span class="toc-text">并行计算模型及性能评测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">并行计算模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PRAM%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.1.</span> <span class="toc-text">PRAM模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">基本概念</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BSP%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.2.</span> <span class="toc-text">BSP模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-1"><span class="toc-number">4.1.2.1.</span> <span class="toc-text">基本概念</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LogP%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.3.</span> <span class="toc-text">LogP模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">4.1.3.1.</span> <span class="toc-text">概念</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E8%AF%84%E6%B5%8B"><span class="toc-number">4.2.</span> <span class="toc-text">性能评测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E7%BA%A7%E6%80%A7%E8%83%BD%E8%AF%84%E6%B5%8B"><span class="toc-number">4.2.1.</span> <span class="toc-text">机器级性能评测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E7%BA%A7%E6%80%A7%E8%83%BD%E8%AF%84%E6%B5%8B"><span class="toc-number">4.2.2.</span> <span class="toc-text">算法级性能评测</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Amdahl%E5%AE%9A%E5%BE%8B"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">Amdahl定律</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Gustafson%E5%AE%9A%E5%BE%8B"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">Gustafson定律</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Sun-Ni%E5%AE%9A%E5%BE%8B"><span class="toc-number">4.2.2.3.</span> <span class="toc-text">Sun &amp; Ni定律</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E7%BA%A7%E6%80%A7%E8%83%BD%E8%AF%84%E6%B5%8B"><span class="toc-number">4.2.3.</span> <span class="toc-text">程序级性能评测</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AD%89%E6%95%88%E7%8E%87%E6%B5%8B%E9%80%9F%EF%BC%88Efficiency-Metrics%EF%BC%89"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">等效率测速（Efficiency Metrics）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1"><span class="toc-number">5.</span> <span class="toc-text">并行算法设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%92%E5%88%86"><span class="toc-number">5.1.</span> <span class="toc-text">划分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%9F%E5%88%92%E5%88%86"><span class="toc-number">5.1.1.</span> <span class="toc-text">域划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%9F%E8%83%BD%E5%88%92%E5%88%86"><span class="toc-number">5.1.2.</span> <span class="toc-text">功能划分</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E4%BF%A1"><span class="toc-number">5.2.</span> <span class="toc-text">通信</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E7%A7%8D%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.2.1.</span> <span class="toc-text">四种通信模式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%84%E5%90%88"><span class="toc-number">5.3.</span> <span class="toc-text">组合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A8%E9%9D%A2-%E5%AE%B9%E7%A7%AF%E6%95%88%E5%BA%94%EF%BC%88Surface-to-Volume-Effects%EF%BC%89"><span class="toc-number">5.3.1.</span> <span class="toc-text">表面-容积效应（Surface-to-Volume Effects）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%A0%E5%B0%84"><span class="toc-number">5.4.</span> <span class="toc-text">映射</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E7%AD%96%E7%95%A5"><span class="toc-number">5.4.1.</span> <span class="toc-text">两种策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1%E7%AE%97%E6%B3%95"><span class="toc-number">5.4.2.</span> <span class="toc-text">负载平衡算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="toc-number">5.4.3.</span> <span class="toc-text">任务调度算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80"><span class="toc-number">6.</span> <span class="toc-text">并行程序设计基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Cannon"><span class="toc-number">6.1.</span> <span class="toc-text">Cannon</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%8F%8F%E8%BF%B0"><span class="toc-number">6.1.1.</span> <span class="toc-text">算法描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">6.1.2.</span> <span class="toc-text">复杂度分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DNS"><span class="toc-number">6.2.</span> <span class="toc-text">DNS</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OpenMP"><span class="toc-number">7.</span> <span class="toc-text">OpenMP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFOpenMP"><span class="toc-number">7.1.</span> <span class="toc-text">什么是OpenMP</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fork-Join%E6%A8%A1%E5%9E%8B"><span class="toc-number">7.2.</span> <span class="toc-text">Fork-Join模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E5%99%A8%E6%8C%87%E4%BB%A4"><span class="toc-number">7.3.</span> <span class="toc-text">编译器指令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%BC%E5%BC%8F"><span class="toc-number">7.3.1.</span> <span class="toc-text">格式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BA%93%E5%87%BD%E6%95%B0"><span class="toc-number">7.4.</span> <span class="toc-text">运行时库函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">7.5.</span> <span class="toc-text">环境变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MPI"><span class="toc-number">8.</span> <span class="toc-text">MPI</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-2"><span class="toc-number">8.1.</span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%AE%AF%E5%9F%9F"><span class="toc-number">8.1.1.</span> <span class="toc-text">通讯域</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">8.2.</span> <span class="toc-text">常用函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop-and-MapReduce"><span class="toc-number">9.</span> <span class="toc-text">Hadoop and MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">9.1.</span> <span class="toc-text">Hadoop是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop%E7%89%B9%E7%82%B9"><span class="toc-number">9.2.</span> <span class="toc-text">Hadoop特点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">9.2.1.</span> <span class="toc-text">高可靠性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%89%A9%E5%B1%95%E6%80%A7"><span class="toc-number">9.2.2.</span> <span class="toc-text">高扩展性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E6%80%A7"><span class="toc-number">9.2.3.</span> <span class="toc-text">高效性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E5%AE%B9%E9%94%99%E6%80%A7"><span class="toc-number">9.2.4.</span> <span class="toc-text">高容错性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop%E7%BB%84%E6%88%90"><span class="toc-number">9.3.</span> <span class="toc-text">Hadoop组成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hadoop1-x%E3%80%812-x%E3%80%813-x%E5%8C%BA%E5%88%AB"><span class="toc-number">9.3.1.</span> <span class="toc-text">Hadoop1.x、2.x、3.x区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS"><span class="toc-number">9.3.2.</span> <span class="toc-text">HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YARN%E6%9E%B6%E6%9E%84"><span class="toc-number">9.3.3.</span> <span class="toc-text">YARN架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce"><span class="toc-number">9.3.4.</span> <span class="toc-text">MapReduce</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Container-and-Docker"><span class="toc-number">10.</span> <span class="toc-text">Container and Docker</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Docker-commands"><span class="toc-number">10.1.</span> <span class="toc-text">Docker commands</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By hu1hu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://www.hu1hu.top/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script src="/js/headerNumbering.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body></html>